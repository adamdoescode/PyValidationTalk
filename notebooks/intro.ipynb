{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd.read_csv is NOT all you need: DataFrame validation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Me\n",
    "\n",
    "- *Data Analyst/Scientist*, or maybe just *Data Tradie* (credit to **Kale Miller** for this term)\n",
    "- Deals with smol data; from ~5 to 1e7 rows.\n",
    "  - Once had to use a generator loop in python to parse something too big to fit into memory.\n",
    "- Training in *Biostatistics* (but no one can prepare you for real world datasets).\n",
    "- Background in biology, bioinformatics.\n",
    "- Some training in R\n",
    "- self-taught pythonista from Udemy, trying pandas before v0.20.0, these meetups, and using it in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why validate anyway?\n",
    "\n",
    "Real world data is messy and strange!\n",
    "\n",
    "- Typos.\n",
    "- Excel magic behaviour.\n",
    "- No one actually knows about [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601).\n",
    "- Sometimes numeric rows get cast to string in csv files ü§∑‚Äç‚ôÄÔ∏è\n",
    "- Someone put a text comment in a numeric column\n",
    "- Your own code introduced something cursed\n",
    "\n",
    "## The goal is to **avoid complexity in your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>int between 0 and 1e6</th>\n",
       "      <th>float between -1 and 1</th>\n",
       "      <th>no nulls allowed</th>\n",
       "      <th>iso 8601 compliant date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>row0</td>\n",
       "      <td>934944</td>\n",
       "      <td>-0.751395</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>row1</td>\n",
       "      <td>842425</td>\n",
       "      <td>0.113027</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text  int between 0 and 1e6  float between -1 and 1  no nulls allowed  \\\n",
       "0  row0                 934944               -0.751395             False   \n",
       "1  row1                 842425                0.113027              True   \n",
       "\n",
       "  iso 8601 compliant date  \n",
       "0              2021-01-01  \n",
       "1              2021-01-02  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>int between 0 and 1e6</th>\n",
       "      <th>float between -1 and 1</th>\n",
       "      <th>no nulls allowed</th>\n",
       "      <th>iso 8601 compliant date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>row0</td>\n",
       "      <td>934944.0</td>\n",
       "      <td>-0.751395</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>row1</td>\n",
       "      <td>842425.0</td>\n",
       "      <td>0.113027</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text  int between 0 and 1e6  float between -1 and 1 no nulls allowed  \\\n",
       "0  row0               934944.0               -0.751395            False   \n",
       "1  row1               842425.0                0.113027             True   \n",
       "\n",
       "  iso 8601 compliant date  \n",
       "0              2021-01-01  \n",
       "1              2021-01-02  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "text                        object\n",
       "int between 0 and 1e6        int64\n",
       "float between -1 and 1     float64\n",
       "no nulls allowed              bool\n",
       "iso 8601 compliant date     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "text                        object\n",
       "int between 0 and 1e6      float64\n",
       "float between -1 and 1     float64\n",
       "no nulls allowed            object\n",
       "iso 8601 compliant date     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import some good data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PyVal import config\n",
    "\n",
    "good_data = pd.read_csv(config.good_data, index_col=0)\n",
    "spicy_data = pd.read_csv(config.spicy_data, index_col=0)\n",
    "display(good_data.head(2), spicy_data.head(2))\n",
    "display(good_data.dtypes, spicy_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Urgh! Our boolean col is an \"object\" lets add a check to fix it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_no_nulls_cols(column: pd.Series, fill_value=False) -> pd.Series:\n",
    "    \"\"\"Removes nulls from a column\"\"\"\n",
    "    return column.fillna(fill_value).astype(bool)\n",
    "\n",
    "\n",
    "validated = spicy_data.copy()\n",
    "validated[\"no nulls allowed\"] = validated[\"no nulls allowed\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And \"int between 0 and 1e6\" is not an `int` type... because it has a `float` in it üôÉ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     934944.0\n",
       "1     842425.0\n",
       "2     220216.0\n",
       "3     138980.0\n",
       "4     907058.0\n",
       "5     396576.0\n",
       "6     870306.0\n",
       "7     981140.0\n",
       "8     266363.0\n",
       "9     143593.0\n",
       "10        -1.0\n",
       "Name: int between 0 and 1e6, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spicy_data[\"int between 0 and 1e6\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WAIT NO - it has a negative number in it!\n",
    "\n",
    "Checking types didn't even show us that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated[\"int between 0 and 1e6\"] = (\n",
    "    validated[\"int between 0 and 1e6\"].astype(int).mask(lambda x: x <= 0, np.nan)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetimes are great and never a problem!!\n",
    "\n",
    "Alright it's fine... at least we can handle the dates right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# all good!\n",
    "validated[\"iso 8601 compliant date\"] = pd.to_datetime(\n",
    "    good_data[\"iso 8601 compliant date\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haha just kidding, we literally can't recover from the classic DD-MM or MM-DD ambiguity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# pd.to_datetime(spicy_data[\"iso 8601 compliant date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S you can usually get around this by knowing some things about your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$ - $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okay *all* data is a mess, how do we fix it?\n",
    "\n",
    "- You could deal with validation by...\n",
    "- manually editing the raw data (bad!!)\n",
    "- adding branching logic whenever you encounter an input data problem (pretty bad)\n",
    "- adding ad-hoc checks in your code (better - but will create a mess)\n",
    "- writing your own validation code that runs before your processing/analysis code (better)\n",
    "- using an existing tool to do the validation for you (ideal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roll your own validation schema\n",
    "\n",
    "Please don't do this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This data is good so we should get to this statement...\n",
      "Task failed succesfully with error: Column 'int between 0 and 1e6' has incorrect data type\n"
     ]
    }
   ],
   "source": [
    "# we need a dodgy function to do the validation with...\n",
    "def validate_data(data: pd.DataFrame, schema: dict) -> pd.DataFrame:\n",
    "    \"\"\"Urgh this is a bit messy to debug if something is broken...\"\"\"\n",
    "    for col, dtype in schema[\"dtypes\"].items():\n",
    "        if col not in data:\n",
    "            raise ValueError(f\"Missing column: {col}\")\n",
    "        if not all(isinstance(val, dtype) for val in data[col]):\n",
    "            raise TypeError(f\"Column '{col}' has incorrect data type\")\n",
    "\n",
    "        checks = schema[\"checks\"].get(col, [])\n",
    "        if checks:\n",
    "            for check in checks:\n",
    "                if not all(check(val) for val in data[col]):\n",
    "                    raise ValueError(f\"Column '{col}' failed validation checks\")\n",
    "    return data\n",
    "\n",
    "\n",
    "# homebrew schema written as nested dict[dict]\n",
    "my_dodgy_schema = {\n",
    "    \"dtypes\": {\n",
    "        \"text\": object,\n",
    "        \"int between 0 and 1e6\": int,\n",
    "        \"float between -1 and 1\": float,\n",
    "        \"no nulls allowed\": bool,\n",
    "    },\n",
    "    \"checks\": {\n",
    "        \"text\": None,\n",
    "        \"int between 0 and 1e6\": [lambda x: 0 <= x <= 1e6],\n",
    "        \"float between -1 and 1\": [lambda x: -1 <= x <= 1],\n",
    "        \"no nulls allowed\": [lambda x: type(x) is bool],\n",
    "    },\n",
    "}\n",
    "\n",
    "# check with known good\n",
    "validated_good = good_data.copy()\n",
    "# Validate good_data\n",
    "try:\n",
    "    validated_good = validate_data(good_data.copy(), my_dodgy_schema)\n",
    "    print(\"This data is good so we should get to this statement...\")\n",
    "except (ValueError, TypeError) as e:\n",
    "    print(f\"Task failed succesfully with error: {e}\")\n",
    "\n",
    "# (Un?)Validate the bad data\n",
    "try:\n",
    "    validated_spicy = validate_data(spicy_data.copy(), my_dodgy_schema)\n",
    "    print(\"Should NOT get to this statement!!\")\n",
    "except (ValueError, TypeError) as e:\n",
    "    print(f\"Task failed succesfully with error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay so that works - why is this bad?\n",
    "\n",
    "- You, the overworked developer who dreams of playing video games tonight, have to maintain it.\n",
    "- You have to test it to make sure it works.\n",
    "- There are a lot of ways validation can go wrong and you have just discovered 0.0001% of those ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeing the light: Strategies and Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fear not young data tradie! We can stand on the shoulders of giants ‚ù§Ô∏è\n",
    "- Other people have written tools to help us:\n",
    "  - Pandera validation library\n",
    "  - pola.rs lazy tables\n",
    "  - `pd.DataFrame.astype()` and `pd.to_datetime()`.\n",
    "  - Pydantic\n",
    "  - python *schema*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandera: you could probably get pretty far using this one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you...\n",
    "- are using pandas, pola.rs, dask, etc.\n",
    "- like it when someone else sorted out a lot of the edge-cases for you\n",
    "- deal with small, heterogenous datasets\n",
    "- like clean and simple syntax\n",
    "\n",
    "An example using the schema above:  \n",
    "*Hey Gemini, re-write this custom schema as a Pandera DataFrameSchema:*  \n",
    "*P.S I re-wrote some of this to show off the default check types which gemini is unaware of but translating schemas is bread-and-butter for LLMs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The good dataset passed üòé\n",
      "The bad dataset failed with error: Column 'text' failed element-wise validator number 0: <Check <lambda>> failure cases: 0\n"
     ]
    }
   ],
   "source": [
    "import pandera as pa\n",
    "from pandera.errors import SchemaError\n",
    "\n",
    "# pandera comes with built in checkers we can use:\n",
    "int_0_to_1e6 = pa.Check.in_range(0, 1e6)\n",
    "float_minus_pos_1 = pa.Check.in_range(-1, 1)\n",
    "# but we can always write our own with lambda or functions.\n",
    "starts_with_row = pa.Check(lambda s: s.str.startswith(\"row\"))\n",
    "\n",
    "# this is how we define a pandera schema\n",
    "my_pandera_schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"text\": pa.Column(str, starts_with_row),\n",
    "        \"int between 0 and 1e6\": pa.Column(int, checks=int_0_to_1e6),\n",
    "        \"float between -1 and 1\": pa.Column(float, checks=float_minus_pos_1),\n",
    "        \"no nulls allowed\": pa.Column(bool),\n",
    "    }\n",
    ")\n",
    "\n",
    "good_pandera = my_pandera_schema(good_data)\n",
    "print(\"The good dataset passed üòé\")\n",
    "try:\n",
    "    spicy_pandera = my_pandera_schema(spicy_data)\n",
    "    print(\"If we got here my talk is going poorly ü´¢\")\n",
    "except SchemaError as e:\n",
    "    print(f\"The bad dataset failed with error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazy Pola.rs üêª‚Äç‚ùÑÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Polars does what Pandas does... but has the benefit of learning from the mistakes Pandas had to discover.\n",
    "- Polars implements `lazy evaluation` through its Lazy API.\n",
    "- This comes with some schema functionality!\n",
    "- But it only covers typing and not validation ü•≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While pandas doesn't have much validation out of the box it has some *very useful* functions:\n",
    "- `pd.to_datetime`\n",
    "- `pd.Series.astype`\n",
    "- `pd.Series.fillna`\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyValidationTalk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
