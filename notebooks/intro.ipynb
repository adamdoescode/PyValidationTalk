{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd.read_csv is NOT all you need: DataFrame validation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Me\n",
    "\n",
    "- *Data Analyst/Scientist*, or maybe just *Data Tradie* (credit to **Kale Miller** for this term)\n",
    "- Deals with smol data; from ~5 to 1e7 rows.\n",
    "  - Once had to use a generator loop in python to parse something too big to fit into memory.\n",
    "- Training in *Biostatistics* (but no one can prepare you for real world datasets).\n",
    "- Background in biology, bioinformatics.\n",
    "- Some training in R\n",
    "- self-taught pythonista from Udemy, trying pandas before v0.20.0, these meetups, and using it in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why validate anyway?\n",
    "\n",
    "Real world data is messy and strange!\n",
    "\n",
    "- Typos.\n",
    "- Excel magic behaviour.\n",
    "- No one actually knows about [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601).\n",
    "- Sometimes numeric rows get cast to string in csv files ü§∑‚Äç‚ôÄÔ∏è\n",
    "- Someone put a text comment in a numeric column\n",
    "- Your own code introduced something cursed\n",
    "\n",
    "## The goal is to **avoid complexity in your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>int between 0 and 1e6</th>\n",
       "      <th>float between -1 and 1</th>\n",
       "      <th>no nulls allowed</th>\n",
       "      <th>iso 8601 compliant date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>row0</td>\n",
       "      <td>934944</td>\n",
       "      <td>-0.751395</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>row1</td>\n",
       "      <td>842425</td>\n",
       "      <td>0.113027</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text  int between 0 and 1e6  float between -1 and 1  no nulls allowed  \\\n",
       "0  row0                 934944               -0.751395             False   \n",
       "1  row1                 842425                0.113027              True   \n",
       "\n",
       "  iso 8601 compliant date  \n",
       "0              2021-01-01  \n",
       "1              2021-01-02  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>int between 0 and 1e6</th>\n",
       "      <th>float between -1 and 1</th>\n",
       "      <th>no nulls allowed</th>\n",
       "      <th>iso 8601 compliant date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>row0</td>\n",
       "      <td>934944.0</td>\n",
       "      <td>-0.751395</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>row1</td>\n",
       "      <td>842425.0</td>\n",
       "      <td>0.113027</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text  int between 0 and 1e6  float between -1 and 1 no nulls allowed  \\\n",
       "0  row0               934944.0               -0.751395            False   \n",
       "1  row1               842425.0                0.113027             True   \n",
       "\n",
       "  iso 8601 compliant date  \n",
       "0              2021-01-01  \n",
       "1              2021-01-02  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "text                        object\n",
       "int between 0 and 1e6        int64\n",
       "float between -1 and 1     float64\n",
       "no nulls allowed              bool\n",
       "iso 8601 compliant date     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "text                        object\n",
       "int between 0 and 1e6      float64\n",
       "float between -1 and 1     float64\n",
       "no nulls allowed            object\n",
       "iso 8601 compliant date     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import some good data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PyVal import config\n",
    "\n",
    "good_data = pd.read_csv(config.good_data, index_col=0)\n",
    "spicy_data = pd.read_csv(config.spicy_data, index_col=0)\n",
    "display(good_data.head(2), spicy_data.head(2))\n",
    "display(good_data.dtypes, spicy_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Urgh! Our boolean col is an \"object\" lets add a check to fix it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_no_nulls_cols(column: pd.Series, fill_value=False) -> pd.Series:\n",
    "    \"\"\"Removes nulls from a column\"\"\"\n",
    "    return column.fillna(fill_value).astype(bool)\n",
    "\n",
    "\n",
    "validated = spicy_data.copy()\n",
    "validated[\"no nulls allowed\"] = validated[\"no nulls allowed\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And \"int between 0 and 1e6\" is not an `int` type... because it has a `float` in it üôÉ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     934944.0\n",
       "1     842425.0\n",
       "2     220216.0\n",
       "3     138980.0\n",
       "4     907058.0\n",
       "5     396576.0\n",
       "6     870306.0\n",
       "7     981140.0\n",
       "8     266363.0\n",
       "9     143593.0\n",
       "10        -1.0\n",
       "Name: int between 0 and 1e6, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spicy_data[\"int between 0 and 1e6\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WAIT NO - it has a negative number in it!\n",
    "\n",
    "Checking types didn't even show us that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated[\"int between 0 and 1e6\"] = (\n",
    "    validated[\"int between 0 and 1e6\"].astype(int).mask(lambda x: x <= 0, np.nan)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetimes are great and never a problem!!\n",
    "\n",
    "Alright it's fine... at least we can handle the dates right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all good!\n",
    "validated[\"iso 8601 compliant date\"] = pd.to_datetime(good_data[\"iso 8601 compliant date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haha just kidding, we literally can't recover from the classic DD-MM or MM-DD ambiguity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"10-10-2021\" doesn't match format \"%Y-%m-%d\", at position 10. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspicy_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miso 8601 compliant date\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/PyValidationTalk/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:1067\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1067\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[0;32m~/miniconda3/envs/PyValidationTalk/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PyValidationTalk/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    457\u001b[0m     arg,\n\u001b[1;32m    458\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data \"10-10-2021\" doesn't match format \"%Y-%m-%d\", at position 10. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "pd.to_datetime(spicy_data[\"iso 8601 compliant date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S you can usually get around this by knowing some things about your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$ - $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okay *all* data is a mess, how do we fix it?\n",
    "\n",
    "- You could deal with validation by...\n",
    "- manually editing the raw data (bad!!)\n",
    "- adding branching logic whenever you encounter an input data problem (pretty bad)\n",
    "- adding ad-hoc checks in your code (better - but will create a mess)\n",
    "- writing your own validation code that runs before your processing/analysis code (better)\n",
    "- using an existing tool to do the validation for you (ideal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roll your own validation schema\n",
    "\n",
    "Please don't do this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This data is good so we should get to this statement...\n",
      "Task failed succesfully with error: Column 'int between 0 and 1e6' has incorrect data type\n"
     ]
    }
   ],
   "source": [
    "my_spicy_data_schema = {\n",
    "    \"dtypes\" : {\n",
    "        \"text\": object,\n",
    "        \"int between 0 and 1e6\": int,\n",
    "        \"float between -1 and 1\": float,\n",
    "        \"no nulls allowed\": bool,\n",
    "    },\n",
    "    \"checks\": {\n",
    "        \"text\": None,\n",
    "        \"int between 0 and 1e6\": [lambda x: 0 <= x <= 1e6],\n",
    "        \"float between -1 and 1\": [lambda x: -1 <= x <= 1],\n",
    "        \"no nulls allowed\": [lambda x: type(x) is bool],\n",
    "    }\n",
    "}\n",
    "# check with known good\n",
    "validated_good = good_data.copy()\n",
    "\n",
    "def validate_data(data: pd.DataFrame, schema: dict) -> pd.DataFrame:\n",
    "    \"\"\"Urgh this is a bit messy to debug if something is broken...\"\"\"\n",
    "    for col, dtype in schema[\"dtypes\"].items():\n",
    "        if col not in data:\n",
    "            raise ValueError(f\"Missing column: {col}\")\n",
    "        if not all(isinstance(val, dtype) for val in data[col]):\n",
    "            raise TypeError(f\"Column '{col}' has incorrect data type\")\n",
    "        \n",
    "        checks = schema[\"checks\"].get(col, [])\n",
    "        if checks:\n",
    "            for check in checks:\n",
    "                if not all(check(val) for val in data[col]):\n",
    "                    raise ValueError(f\"Column '{col}' failed validation checks\")\n",
    "    return data\n",
    "\n",
    "# Validate good_data\n",
    "try:\n",
    "    validated_good = validate_data(good_data.copy(), my_spicy_data_schema)\n",
    "    print(\"This data is good so we should get to this statement...\")\n",
    "except (ValueError, TypeError) as e:\n",
    "    print(f\"Task failed succesfully with error: {e}\")\n",
    "\n",
    "# (Un?)Validate the bad data\n",
    "try:\n",
    "    validated_spicy = validate_data(spicy_data.copy(), my_spicy_data_schema)\n",
    "    print(\"Should NOT get to this statement!!\")\n",
    "except (ValueError, TypeError) as e:\n",
    "    print(f\"Task failed succesfully with error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay so that works - why is this bad?\n",
    "\n",
    "- You, the overworked developer who dreams of playing video games tonight, have to maintain it.\n",
    "- You have to test it to make sure it works.\n",
    "- There are a lot of ways validation can go wrong and you have just discovered 0.0001% of those ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeing the light: Strategies and Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fear not young data tradie! We can stand on the shoulders of giants ‚ù§Ô∏è\n",
    "- Other people have written tools to help us:\n",
    "  - Pandera validation library\n",
    "  - pola.rs lazy tables\n",
    "  - `pd.DataFrame.astype()` and `pd.to_datetime()`.\n",
    "  - Pydantic\n",
    "  - python *schema*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandera: you could probably get pretty far using this one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you...\n",
    "- are using pandas, pola.rs, dask, etc.\n",
    "- like it when someone else sorted out a lot of the edge-cases for you\n",
    "- deal with small, heterogenous datasets\n",
    "- like clean and simple syntax\n",
    "\n",
    "An example using the schema above:  \n",
    "*Hey Gemini, re-write this custom schema as a Pandera DataFrameSchema:*  \n",
    "*P.S I re-wrote some of this to show off the default check types which gemini is unaware of but translating schemas is bread-and-butter for LLMs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The good dataset passed üòé\n",
      "The bad dataset failed with error: Column 'text' failed element-wise validator number 0: <Check <lambda>> failure cases: 0\n"
     ]
    }
   ],
   "source": [
    "import pandera as pa\n",
    "from pandera.errors import SchemaError\n",
    "\n",
    "# pandera comes with built in checkers we can use:\n",
    "int_0_to_1e6 = pa.Check.in_range(0, 1e6)\n",
    "float_minus_pos_1 = pa.Check.in_range(-1, 1)\n",
    "# but we can always write our own with lambda or functions.\n",
    "starts_with_row = pa.Check(lambda s: s.str.startswith(\"row\"))\n",
    "\n",
    "# this is how we define a pandera schema\n",
    "my_pandera_schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"text\": pa.Column(str, starts_with_row),\n",
    "        \"int between 0 and 1e6\": pa.Column(int, checks=int_0_to_1e6),\n",
    "        \"float between -1 and 1\": pa.Column(float, checks=float_minus_pos_1),\n",
    "        \"no nulls allowed\": pa.Column(bool),\n",
    "    }\n",
    ")\n",
    "\n",
    "good_pandera = my_pandera_schema(good_data)\n",
    "print(\"The good dataset passed üòé\")\n",
    "try:\n",
    "    spicy_pandera = my_pandera_schema(spicy_data)\n",
    "    print(\"If we got here my talk is going poorly ü´¢\")\n",
    "except SchemaError as e:\n",
    "    print(f\"The bad dataset failed with error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazy Pola.rs üêª‚Äç‚ùÑÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Polars does what Pandas does... but has the benefit of learning from the mistakes Pandas had to discover.\n",
    "- Polars implements `lazy evaluation` through its Lazy API.\n",
    "- This comes with some schema functionality!\n",
    "- But it only covers typing and not validation ü•≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'polars'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpolars\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpl\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'polars'"
     ]
    }
   ],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While pandas doesn't have much validation out of the box it has some *very useful* functions:\n",
    "- `pd.to_datetime`\n",
    "- `pd.Series.astype`\n",
    "- `pd.Series.fillna`\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyValidationTalk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
